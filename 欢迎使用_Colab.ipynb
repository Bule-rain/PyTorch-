{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bule-rain/PyTorch-/blob/main/%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# æ·±åº¦å­¦ä¹ ç›¸å…³åº“\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import py7zr  # éœ€è¦å®‰è£…: !pip install py7zr\n",
        "from google.colab import drive\n",
        "\n",
        "# è®¾ç½®éšæœºç§å­\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# CIFAR-10ç±»åˆ«æ ‡ç­¾\n",
        "CLASS_NAMES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "def mount_drive_and_check():\n",
        "    \"\"\"æŒ‚è½½Driveå¹¶æ£€æŸ¥æ–‡ä»¶\"\"\"\n",
        "    print(\"æ­£åœ¨æŒ‚è½½Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # æ£€æŸ¥cifar-10.zipæ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
        "    zip_path = '/content/drive/MyDrive/cifar-10.zip'\n",
        "    if os.path.exists(zip_path):\n",
        "        print(f\"âœ… æ‰¾åˆ°cifar-10.zipæ–‡ä»¶: {zip_path}\")\n",
        "        print(f\"æ–‡ä»¶å¤§å°: {os.path.getsize(zip_path) / (1024*1024):.1f} MB\")\n",
        "        return zip_path\n",
        "    else:\n",
        "        print(\"âŒ æœªæ‰¾åˆ°cifar-10.zipæ–‡ä»¶\")\n",
        "        print(\"è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®\")\n",
        "        return None\n",
        "\n",
        "def explore_zip_contents(zip_path):\n",
        "    \"\"\"æ¢ç´¢zipæ–‡ä»¶å†…å®¹\"\"\"\n",
        "    print(\"æ­£åœ¨æ¢ç´¢zipæ–‡ä»¶å†…å®¹...\")\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        file_list = zip_ref.namelist()\n",
        "        print(f\"zipæ–‡ä»¶ä¸­åŒ…å« {len(file_list)} ä¸ªæ–‡ä»¶:\")\n",
        "        for file in file_list:\n",
        "            print(f\"  - {file}\")\n",
        "\n",
        "        # æŸ¥æ‰¾7zæ–‡ä»¶\n",
        "        sevenZ_files = [f for f in file_list if f.endswith('.7z')]\n",
        "        csv_files = [f for f in file_list if f.endswith('.csv')]\n",
        "\n",
        "        print(f\"\\næ‰¾åˆ° {len(sevenZ_files)} ä¸ª7zæ–‡ä»¶:\")\n",
        "        for sz_file in sevenZ_files:\n",
        "            print(f\"  - {sz_file}\")\n",
        "\n",
        "        print(f\"æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶:\")\n",
        "        for csv_file in csv_files:\n",
        "            print(f\"  - {csv_file}\")\n",
        "\n",
        "        return file_list, sevenZ_files, csv_files\n",
        "\n",
        "def extract_and_load_data(zip_path):\n",
        "    \"\"\"è§£å‹zipå’Œ7zæ–‡ä»¶ï¼ŒåŠ è½½ æ ‡ç­¾CSV + å›¾ç‰‡æ•°æ®\"\"\"\n",
        "    print(\"æ­£åœ¨è§£å‹æ–‡ä»¶...\")\n",
        "\n",
        "    # åˆ›å»ºä¸´æ—¶ç›®å½•\n",
        "    temp_dir = '/content/temp_cifar'\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    # é¦–å…ˆè§£å‹zipæ–‡ä»¶\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(temp_dir)\n",
        "        print(\"âœ… zipæ–‡ä»¶è§£å‹å®Œæˆ\")\n",
        "\n",
        "    # æŸ¥æ‰¾è§£å‹åçš„æ–‡ä»¶\n",
        "    extracted_files = os.listdir(temp_dir)\n",
        "    print(f\"è§£å‹åçš„æ–‡ä»¶: {extracted_files}\")\n",
        "\n",
        "    # åˆå§‹åŒ–æ•°æ®å˜é‡\n",
        "    train_labels_df = None  # å­˜è®­ç»ƒæ ‡ç­¾\n",
        "    test_images = None      # å­˜æµ‹è¯•å›¾ç‰‡\n",
        "    sample_submission = None# å­˜æäº¤æ ·æœ¬\n",
        "    train_images = None     # å­˜è®­ç»ƒå›¾ç‰‡ï¼ˆå¯é€‰ï¼Œè‹¥éœ€è¦ä»7zåŠ è½½è®­ç»ƒå›¾ï¼‰\n",
        "\n",
        "    # å¤„ç†CSVæ–‡ä»¶ï¼ˆæ ‡ç­¾ã€æäº¤æ ·æœ¬ï¼‰\n",
        "    for file in extracted_files:\n",
        "        if file.endswith('.csv'):\n",
        "            file_path = os.path.join(temp_dir, file)\n",
        "            if 'trainLabels' in file:  # åŒ¹é…è®­ç»ƒæ ‡ç­¾æ–‡ä»¶\n",
        "                train_labels_df = pd.read_csv(file_path)\n",
        "                print(f\"âœ… åŠ è½½è®­ç»ƒæ ‡ç­¾æ•°æ®: {train_labels_df.shape}\")\n",
        "            elif 'sampleSubmission' in file:  # åŒ¹é…æäº¤æ ·æœ¬\n",
        "                sample_submission = pd.read_csv(file_path)\n",
        "                print(f\"âœ… åŠ è½½æäº¤æ ·æœ¬: {sample_submission.shape}\")\n",
        "\n",
        "    # å¤„ç†7zæ–‡ä»¶ï¼ˆæå–å›¾ç‰‡ï¼‰\n",
        "    for file in extracted_files:\n",
        "        if file.endswith('.7z'):\n",
        "            print(f\"æ­£åœ¨è§£å‹7zæ–‡ä»¶: {file}\")\n",
        "            sevenZ_path = os.path.join(temp_dir, file)\n",
        "\n",
        "            try:\n",
        "                with py7zr.SevenZipFile(sevenZ_path, mode='r') as archive:\n",
        "                    archive.extractall(path=temp_dir)\n",
        "                    print(f\"âœ… {file} è§£å‹å®Œæˆ\")\n",
        "\n",
        "                    # åŒºåˆ†è®­ç»ƒ/æµ‹è¯•7zï¼ŒåŠ è½½å›¾ç‰‡\n",
        "                    if 'train' in file:\n",
        "                        train_img_dir = os.path.join(temp_dir, 'train')  # å‡è®¾è§£å‹åˆ° train ç›®å½•\n",
        "                        if os.path.exists(train_img_dir):\n",
        "                            train_images = []\n",
        "                            for img_name in sorted(os.listdir(train_img_dir)):\n",
        "                                img_path = os.path.join(train_img_dir, img_name)\n",
        "                                img = Image.open(img_path).convert('RGB')\n",
        "                                img = np.array(img)\n",
        "                                train_images.append(img)\n",
        "                            train_images = np.array(train_images)\n",
        "                            print(f\"âœ… åŠ è½½è®­ç»ƒå›¾ç‰‡ {train_images.shape[0]} å¼ \")\n",
        "                    elif 'test' in file:\n",
        "                        test_img_dir = os.path.join(temp_dir, 'test')  # å‡è®¾è§£å‹åˆ° test ç›®å½•\n",
        "                        if os.path.exists(test_img_dir):\n",
        "                            test_images = []\n",
        "                            for img_name in sorted(os.listdir(test_img_dir)):\n",
        "                                img_path = os.path.join(test_img_dir, img_name)\n",
        "                                img = Image.open(img_path).convert('RGB')\n",
        "                                img = np.array(img)\n",
        "                                test_images.append(img)\n",
        "                            test_images = np.array(test_images)\n",
        "                            print(f\"âœ… åŠ è½½æµ‹è¯•å›¾ç‰‡ {test_images.shape[0]} å¼ \")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ è§£å‹ {file} å¤±è´¥: {e}\")\n",
        "                continue\n",
        "\n",
        "    # æ•´åˆè®­ç»ƒæ•°æ®ï¼ˆæ ‡ç­¾ + å›¾ç‰‡ï¼‰\n",
        "    if train_labels_df is not None and train_images is not None:\n",
        "        # ç¡®ä¿æ ‡ç­¾å’Œå›¾ç‰‡æ•°é‡åŒ¹é…ï¼ˆCIFAR-10 è®­ç»ƒé›† 50000 å¼ å›¾ + 50000 æ¡æ ‡ç­¾ï¼‰\n",
        "        if len(train_labels_df) == len(train_images):\n",
        "            train_df = pd.DataFrame({\n",
        "                'id': train_labels_df['id'],\n",
        "                'label': train_labels_df['label'],\n",
        "                'image': list(train_images)  # å­˜å›¾ç‰‡æ•°ç»„\n",
        "            })\n",
        "        else:\n",
        "            print(\"âš ï¸ è®­ç»ƒæ ‡ç­¾å’Œå›¾ç‰‡æ•°é‡ä¸åŒ¹é…ï¼Œè·³è¿‡æ•´åˆ\")\n",
        "            train_df = None\n",
        "    else:\n",
        "        train_df = None\n",
        "\n",
        "    # æ„é€ æµ‹è¯•æ•°æ®DataFrameï¼ˆä»…å›¾ç‰‡ï¼Œæäº¤æ—¶ç”¨IDåŒ¹é…ï¼‰\n",
        "    if test_images is not None:\n",
        "        test_df = pd.DataFrame({\n",
        "            'id': range(1, len(test_images)+1),  # å‡è®¾IDä»1å¼€å§‹\n",
        "            'image': list(test_images)\n",
        "        })\n",
        "    else:\n",
        "        test_df = None\n",
        "\n",
        "    return train_df, test_df, sample_submission, temp_dir\n",
        "\n",
        "def cleanup_temp_files(temp_dir):\n",
        "    \"\"\"æ¸…ç†ä¸´æ—¶æ–‡ä»¶\"\"\"\n",
        "    import shutil\n",
        "    if os.path.exists(temp_dir):\n",
        "        shutil.rmtree(temp_dir)\n",
        "        print(f\"âœ… ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†: {temp_dir}\")\n",
        "\n",
        "def load_cifar_data():\n",
        "    \"\"\"å®Œæ•´çš„æ•°æ®åŠ è½½æµç¨‹ï¼ˆé€‚é…å›¾ç‰‡+æ ‡ç­¾ï¼‰\"\"\"\n",
        "    # å®‰è£…py7zrï¼ˆå¦‚æœæ²¡æœ‰å®‰è£…ï¼‰\n",
        "    try:\n",
        "        import py7zr\n",
        "    except ImportError:\n",
        "        print(\"æ­£åœ¨å®‰è£…py7zr...\")\n",
        "        os.system(\"pip install py7zr\")\n",
        "        import py7zr\n",
        "\n",
        "    # æŒ‚è½½Driveå¹¶æ£€æŸ¥æ–‡ä»¶\n",
        "    zip_path = mount_drive_and_check()\n",
        "    if not zip_path:\n",
        "        return None, None, None\n",
        "\n",
        "    # æ¢ç´¢æ–‡ä»¶å†…å®¹\n",
        "    file_list, sevenZ_files, csv_files = explore_zip_contents(zip_path)\n",
        "\n",
        "    # è§£å‹å¹¶åŠ è½½æ•°æ®ï¼ˆå›¾ç‰‡+æ ‡ç­¾ï¼‰\n",
        "    train_df, test_df, sample_submission, temp_dir = extract_and_load_data(zip_path)\n",
        "\n",
        "    # æ•°æ®æ¦‚è§ˆ\n",
        "    if train_df is not None:\n",
        "        print(f\"\\nğŸ“Š è®­ç»ƒæ•°æ®æ¦‚è§ˆ:\")\n",
        "        print(f\"å½¢çŠ¶: {train_df.shape}\")\n",
        "        print(f\"åˆ—å: {list(train_df.columns)}\")\n",
        "        print(train_df.head())\n",
        "\n",
        "    if test_df is not None:\n",
        "        print(f\"\\nğŸ“Š æµ‹è¯•æ•°æ®æ¦‚è§ˆ:\")\n",
        "        print(f\"å½¢çŠ¶: {test_df.shape}\")\n",
        "        print(f\"åˆ—å: {list(test_df.columns)}\")\n",
        "        print(test_df.head())\n",
        "\n",
        "    if sample_submission is not None:\n",
        "        print(f\"\\nğŸ“Š æäº¤æ ·æœ¬æ¦‚è§ˆ:\")\n",
        "        print(f\"å½¢çŠ¶: {sample_submission.shape}\")\n",
        "        print(f\"åˆ—å: {list(sample_submission.columns)}\")\n",
        "        print(sample_submission.head())\n",
        "\n",
        "    # è¯¢é—®æ˜¯å¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
        "    print(f\"\\nä¸´æ—¶æ–‡ä»¶ä¿å­˜åœ¨: {temp_dir}\")\n",
        "    print(\"å¦‚éœ€æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œè¯·è°ƒç”¨: cleanup_temp_files(temp_dir)\")\n",
        "\n",
        "    return train_df, test_df, sample_submission\n",
        "\n",
        "def quick_data_analysis(train_df, test_df, sample_submission):\n",
        "    \"\"\"å¿«é€Ÿæ•°æ®åˆ†æï¼ˆé€‚é…å›¾ç‰‡æ•°æ®ï¼‰\"\"\"\n",
        "    print(\"\\n=== æ•°æ®åˆ†æ ===\")\n",
        "\n",
        "    if train_df is not None:\n",
        "        print(\"è®­ç»ƒæ•°æ®ä¿¡æ¯:\")\n",
        "        print(f\"  å½¢çŠ¶: {train_df.shape}\")\n",
        "        print(f\"  åˆ—å: {list(train_df.columns)}\")\n",
        "        print(f\"  å‰å‡ è¡Œ:\")\n",
        "        print(train_df.head(2))\n",
        "\n",
        "        # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ\n",
        "        if 'label' in train_df.columns:\n",
        "            label_counts = train_df['label'].value_counts().sort_index()\n",
        "            print(f\"\\næ ‡ç­¾åˆ†å¸ƒ:\")\n",
        "            for label, count in label_counts.items():\n",
        "                print(f\"  {label}: {count} å¼ \")\n",
        "\n",
        "    if test_df is not None:\n",
        "        print(\"\\næµ‹è¯•æ•°æ®ä¿¡æ¯:\")\n",
        "        print(f\"  å½¢çŠ¶: {test_df.shape}\")\n",
        "        print(f\"  åˆ—å: {list(test_df.columns)}\")\n",
        "        print(f\"  å‰å‡ è¡Œ:\")\n",
        "        print(test_df.head(2))\n",
        "\n",
        "    if sample_submission is not None:\n",
        "        print(\"\\næäº¤æ ·æœ¬ä¿¡æ¯:\")\n",
        "        print(f\"  å½¢çŠ¶: {sample_submission.shape}\")\n",
        "        print(f\"  åˆ—å: {list(sample_submission.columns)}\")\n",
        "        print(f\"  å‰å‡ è¡Œ:\")\n",
        "        print(sample_submission.head(2))\n",
        "\n",
        "def preprocess_data(train_df, test_df):\n",
        "    \"\"\"æ•°æ®é¢„å¤„ç†ï¼ˆé€‚é…å›¾ç‰‡æ•°ç»„ï¼‰\"\"\"\n",
        "    print(\"\\n=== æ•°æ®é¢„å¤„ç† ===\")\n",
        "\n",
        "    # åˆ›å»ºæ ‡ç­¾æ˜ å°„å­—å…¸\n",
        "    label_to_int = {\n",
        "        'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
        "        'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9\n",
        "    }\n",
        "\n",
        "    # åˆ†ç¦»ç‰¹å¾ï¼ˆå›¾ç‰‡ï¼‰å’Œæ ‡ç­¾\n",
        "    if train_df is not None and 'image' in train_df.columns and 'label' in train_df.columns:\n",
        "        X_train = np.array(train_df['image'].tolist())  # è½¬æˆ numpy æ•°ç»„\n",
        "        # å°†å­—ç¬¦ä¸²æ ‡ç­¾è½¬æ¢ä¸ºæ•°å­—æ ‡ç­¾\n",
        "        y_train = train_df['label'].map(label_to_int).values\n",
        "        print(f\"æ ‡ç­¾è½¬æ¢å®Œæˆï¼š{train_df['label'].iloc[0]} -> {y_train[0]}\")\n",
        "    else:\n",
        "        X_train, y_train = None, None\n",
        "\n",
        "    # å¤„ç†æµ‹è¯•æ•°æ®ï¼ˆå›¾ç‰‡ï¼‰\n",
        "    if test_df is not None and 'image' in test_df.columns:\n",
        "        X_test = np.array(test_df['image'].tolist())\n",
        "        test_ids = test_df['id'].values\n",
        "    else:\n",
        "        X_test, test_ids = None, None\n",
        "\n",
        "    # é‡å¡‘ä¸ºæ ‡å‡†å›¾åƒæ ¼å¼ (32x32x3)\n",
        "    if X_train is not None and X_train.shape[1:] == (32, 32, 3):\n",
        "        print(\"âœ… è®­ç»ƒæ•°æ®å·²ä¸º32x32x3å›¾åƒæ ¼å¼\")\n",
        "    else:\n",
        "        if X_train is not None:\n",
        "            print(f\"âš ï¸  è®­ç»ƒå›¾åƒç»´åº¦å¼‚å¸¸ï¼Œå®é™…å½¢çŠ¶: {X_train.shape}\")\n",
        "\n",
        "    if X_test is not None and X_test.shape[1:] == (32, 32, 3):\n",
        "        print(\"âœ… æµ‹è¯•æ•°æ®å·²ä¸º32x32x3å›¾åƒæ ¼å¼\")\n",
        "    else:\n",
        "        if X_test is not None:\n",
        "            print(f\"âš ï¸  æµ‹è¯•å›¾åƒç»´åº¦å¼‚å¸¸ï¼Œå®é™…å½¢çŠ¶: {X_test.shape}\")\n",
        "\n",
        "    # æ ‡å‡†åŒ–åˆ° [0,1] èŒƒå›´\n",
        "    if X_train is not None:\n",
        "        X_train = X_train.astype('float32') / 255.0\n",
        "        print(f\"âœ… è®­ç»ƒæ•°æ®æ ‡å‡†åŒ–å®Œæˆï¼Œåƒç´ å€¼èŒƒå›´: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
        "    if X_test is not None:\n",
        "        X_test = X_test.astype('float32') / 255.0\n",
        "        print(f\"âœ… æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–å®Œæˆï¼Œåƒç´ å€¼èŒƒå›´: [{X_test.min():.3f}, {X_test.max():.3f}]\")\n",
        "\n",
        "    # æ ‡ç­¾one-hotç¼–ç \n",
        "    y_train_onehot = keras.utils.to_categorical(y_train, 10) if y_train is not None else None\n",
        "\n",
        "    print(f\"\\né¢„å¤„ç†å®Œæˆ:\")\n",
        "    print(f\"  è®­ç»ƒå›¾åƒ: {X_train.shape if X_train is not None else 'None'}\")\n",
        "    print(f\"  è®­ç»ƒæ ‡ç­¾: {y_train_onehot.shape if y_train_onehot is not None else 'None'}\")\n",
        "    print(f\"  æµ‹è¯•å›¾åƒ: {X_test.shape if X_test is not None else 'None'}\")\n",
        "    print(f\"  æ ‡ç­¾èŒƒå›´: {y_train.min()}-{y_train.max()}\" if y_train is not None else \"  æ ‡ç­¾èŒƒå›´: None\")\n",
        "\n",
        "    return X_train, y_train_onehot, X_test, test_ids\n",
        "\n",
        "def create_model():\n",
        "    \"\"\"åˆ›å»ºæ”¹è¿›çš„CNNæ¨¡å‹\"\"\"\n",
        "    model = keras.Sequential([\n",
        "        # ç¬¬ä¸€å±‚å·ç§¯å—\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # ç¬¬äºŒå±‚å·ç§¯å—\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # ç¬¬ä¸‰å±‚å·ç§¯å—\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # å…¨è¿æ¥å±‚\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model_enhanced(model, X_train, y_train):\n",
        "    \"\"\"å¢å¼ºç‰ˆæ¨¡å‹è®­ç»ƒå‡½æ•°\"\"\"\n",
        "    print(\"\\n=== å¼€å§‹è®­ç»ƒ ===\")\n",
        "\n",
        "    # æ£€æŸ¥æ•°æ®\n",
        "    if X_train is None or y_train is None:\n",
        "        print(\"âŒ è®­ç»ƒæ•°æ®æœªæ­£ç¡®åŠ è½½ï¼Œæ— æ³•è®­ç»ƒ\")\n",
        "        return None, None\n",
        "\n",
        "    # æ£€æŸ¥æ•°æ®å½¢çŠ¶\n",
        "    if len(X_train.shape) != 4 or X_train.shape[1:] != (32, 32, 3):\n",
        "        print(f\"âŒ è®­ç»ƒæ•°æ®å½¢çŠ¶ä¸æ­£ç¡®: {X_train.shape}, æœŸæœ›: (N, 32, 32, 3)\")\n",
        "        return None, None\n",
        "\n",
        "    if len(y_train.shape) != 2 or y_train.shape[1] != 10:\n",
        "        print(f\"âŒ æ ‡ç­¾æ•°æ®å½¢çŠ¶ä¸æ­£ç¡®: {y_train.shape}, æœŸæœ›: (N, 10)\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"âœ… æ•°æ®æ£€æŸ¥é€šè¿‡:\")\n",
        "    print(f\"   è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train.shape}\")\n",
        "    print(f\"   æ ‡ç­¾æ•°æ®å½¢çŠ¶: {y_train.shape}\")\n",
        "\n",
        "    # ç¼–è¯‘æ¨¡å‹\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # åˆ†å‰²éªŒè¯é›†\n",
        "        X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "            X_train, y_train,\n",
        "            test_size=0.2,\n",
        "            random_state=42,\n",
        "            stratify=np.argmax(y_train, axis=1)\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… æ•°æ®åˆ†å‰²å®Œæˆ:\")\n",
        "        print(f\"   è®­ç»ƒé›†: {X_train_split.shape[0]} å¼ \")\n",
        "        print(f\"   éªŒè¯é›†: {X_val.shape[0]} å¼ \")\n",
        "\n",
        "        # æ•°æ®å¢å¼º\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=15,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            horizontal_flip=True,\n",
        "            zoom_range=0.1,\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "\n",
        "        # å›è°ƒå‡½æ•°\n",
        "        callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor='val_accuracy',\n",
        "                patience=15,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=7,\n",
        "                min_lr=1e-7,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
        "\n",
        "        # è®¡ç®—æ­¥æ•°\n",
        "        batch_size = 32  # å‡å°æ‰¹æ¬¡å¤§å°é¿å…å†…å­˜é—®é¢˜\n",
        "        steps_per_epoch = max(1, len(X_train_split) // batch_size)\n",
        "\n",
        "        # è®­ç»ƒæ¨¡å‹\n",
        "        history = model.fit(\n",
        "            datagen.flow(X_train_split, y_train_split, batch_size=batch_size),\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            epochs=50,  # å‡å°‘åˆå§‹epochs\n",
        "            validation_data=(X_val, y_val),\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # è®­ç»ƒå®Œæˆåçš„è¯„ä¼°\n",
        "        print(\"\\n=== è®­ç»ƒå®Œæˆ ===\")\n",
        "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "        print(f\"âœ… æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}\")\n",
        "        print(f\"âœ… æœ€ç»ˆéªŒè¯æŸå¤±: {val_loss:.4f}\")\n",
        "\n",
        "        return model, history\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\")\n",
        "        print(\"å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
        "        print(\"1. æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®\")\n",
        "        print(\"2. å‡å°æ‰¹æ¬¡å¤§å°\")\n",
        "        print(\"3. æ£€æŸ¥GPUå†…å­˜æ˜¯å¦è¶³å¤Ÿ\")\n",
        "        return None, None\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨\"\"\"\n",
        "    if history is None:\n",
        "        print(\"âŒ æ²¡æœ‰è®­ç»ƒå†å²æ•°æ®å¯ä»¥ç»˜åˆ¶\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "        # å‡†ç¡®ç‡å›¾è¡¨\n",
        "        ax1.plot(history.history['accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡')\n",
        "        ax1.plot(history.history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡')\n",
        "        ax1.set_title('æ¨¡å‹å‡†ç¡®ç‡')\n",
        "        ax1.set_xlabel('è½®æ¬¡')\n",
        "        ax1.set_ylabel('å‡†ç¡®ç‡')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # æŸå¤±å›¾è¡¨\n",
        "        ax2.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')\n",
        "        ax2.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')\n",
        "        ax2.set_title('æ¨¡å‹æŸå¤±')\n",
        "        ax2.set_xlabel('è½®æ¬¡')\n",
        "        ax2.set_ylabel('æŸå¤±')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ç»˜å›¾æ—¶å‡ºç°é”™è¯¯: {str(e)}\")\n",
        "\n",
        "def prepare_cifar10_data():\n",
        "    \"\"\"å‡†å¤‡CIFAR-10æ•°æ®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥ä»KerasåŠ è½½ï¼‰\"\"\"\n",
        "    try:\n",
        "        # åŠ è½½CIFAR-10æ•°æ®\n",
        "        (X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "        # æ•°æ®é¢„å¤„ç†\n",
        "        X_train = X_train.astype('float32') / 255.0\n",
        "        X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "        # æ ‡ç­¾one-hotç¼–ç \n",
        "        y_train_onehot = keras.utils.to_categorical(y_train, 10)\n",
        "        y_test_onehot = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "        print(f\"âœ… æ•°æ®åŠ è½½å®Œæˆ:\")\n",
        "        print(f\"   è®­ç»ƒé›†: {X_train.shape}\")\n",
        "        print(f\"   æµ‹è¯•é›†: {X_test.shape}\")\n",
        "        print(f\"   è®­ç»ƒæ ‡ç­¾: {y_train_onehot.shape}\")\n",
        "        print(f\"   æµ‹è¯•æ ‡ç­¾: {y_test_onehot.shape}\")\n",
        "\n",
        "        return X_train, y_train_onehot, X_test, y_test_onehot\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "def generate_submission_enhanced(model, X_test, test_ids, sample_submission):\n",
        "    \"\"\"å¢å¼ºç‰ˆæäº¤æ–‡ä»¶ç”Ÿæˆå‡½æ•°\"\"\"\n",
        "    print(\"\\n=== ç”Ÿæˆæäº¤æ–‡ä»¶ ===\")\n",
        "\n",
        "    if X_test is None or sample_submission is None:\n",
        "        print(\"âŒ æµ‹è¯•æ•°æ®æˆ–æäº¤æ ·æœ¬æœªæ­£ç¡®åŠ è½½ï¼Œæ— æ³•ç”Ÿæˆæäº¤æ–‡ä»¶\")\n",
        "        return None\n",
        "\n",
        "    if model is None:\n",
        "        print(\"âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•ç”Ÿæˆé¢„æµ‹\")\n",
        "        return None\n",
        "\n",
        "    print(f\"ğŸ“Š å¼€å§‹é¢„æµ‹ {len(X_test)} å¼ æµ‹è¯•å›¾ç‰‡...\")\n",
        "\n",
        "    # åˆ†æ‰¹é¢„æµ‹ï¼ˆé¿å…å†…å­˜ä¸è¶³ï¼‰\n",
        "    batch_size = 1000\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(0, len(X_test), batch_size):\n",
        "        end_idx = min(i + batch_size, len(X_test))\n",
        "        batch_predictions = model.predict(X_test[i:end_idx], verbose=0)\n",
        "        predictions.append(batch_predictions)\n",
        "\n",
        "        # æ˜¾ç¤ºè¿›åº¦\n",
        "        progress = (end_idx / len(X_test)) * 100\n",
        "        print(f\"é¢„æµ‹è¿›åº¦: {progress:.1f}% ({end_idx}/{len(X_test)})\")\n",
        "\n",
        "    # åˆå¹¶æ‰€æœ‰é¢„æµ‹ç»“æœ\n",
        "    predictions = np.vstack(predictions)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # å°†æ•°å­—æ ‡ç­¾è½¬å›å­—ç¬¦ä¸²æ ‡ç­¾\n",
        "    int_to_label = {\n",
        "        0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
        "        5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'\n",
        "    }\n",
        "\n",
        "    predicted_labels = [int_to_label[pred] for pred in predicted_classes]\n",
        "\n",
        "    # åˆ›å»ºæäº¤æ–‡ä»¶\n",
        "    submission = sample_submission.copy()\n",
        "    submission['label'] = predicted_labels\n",
        "\n",
        "    # éªŒè¯æäº¤æ–‡ä»¶æ ¼å¼\n",
        "    print(f\"\\nğŸ“‹ æäº¤æ–‡ä»¶éªŒè¯:\")\n",
        "    print(f\"   å½¢çŠ¶: {submission.shape}\")\n",
        "    print(f\"   åˆ—å: {list(submission.columns)}\")\n",
        "    print(f\"   IDèŒƒå›´: {submission['id'].min()} - {submission['id'].max()}\")\n",
        "    print(f\"   æ ‡ç­¾ç±»å‹: {submission['label'].dtype}\")\n",
        "\n",
        "    # æ£€æŸ¥é¢„æµ‹åˆ†å¸ƒ\n",
        "    print(f\"\\nğŸ“Š é¢„æµ‹ç»“æœåˆ†å¸ƒ:\")\n",
        "    label_counts = submission['label'].value_counts().sort_index()\n",
        "    for label, count in label_counts.items():\n",
        "        percentage = (count / len(submission)) * 100\n",
        "        print(f\"   {label}: {count:,} å¼  ({percentage:.1f}%)\")\n",
        "\n",
        "    # ä¿å­˜åˆ°Drive\n",
        "    submission_path = '/content/drive/MyDrive/cifar10_submission.csv'\n",
        "    submission.to_csv(submission_path, index=False)\n",
        "\n",
        "    print(f\"\\nâœ… æäº¤æ–‡ä»¶å·²ä¿å­˜: {submission_path}\")\n",
        "    print(f\"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(submission_path) / (1024*1024):.1f} MB\")\n",
        "\n",
        "    # æ˜¾ç¤ºæäº¤æ–‡ä»¶å‰å‡ è¡Œ\n",
        "    print(f\"\\nğŸ“ æäº¤æ–‡ä»¶é¢„è§ˆ:\")\n",
        "    print(submission.head(10))\n",
        "\n",
        "    return submission\n",
        "\n",
        "def validate_submission(submission, sample_submission):\n",
        "    \"\"\"éªŒè¯æäº¤æ–‡ä»¶çš„æ­£ç¡®æ€§\"\"\"\n",
        "    print(\"\\n=== æäº¤æ–‡ä»¶éªŒè¯ ===\")\n",
        "\n",
        "    # æ£€æŸ¥å½¢çŠ¶\n",
        "    if submission.shape == sample_submission.shape:\n",
        "        print(\"âœ… æ–‡ä»¶å½¢çŠ¶æ­£ç¡®\")\n",
        "    else:\n",
        "        print(f\"âŒ æ–‡ä»¶å½¢çŠ¶é”™è¯¯: {submission.shape} vs {sample_submission.shape}\")\n",
        "        return False\n",
        "\n",
        "    # æ£€æŸ¥åˆ—å\n",
        "    if list(submission.columns) == list(sample_submission.columns):\n",
        "        print(\"âœ… åˆ—åæ­£ç¡®\")\n",
        "    else:\n",
        "        print(f\"âŒ åˆ—åé”™è¯¯: {list(submission.columns)} vs {list(sample_submission.columns)}\")\n",
        "        return False\n",
        "\n",
        "    # æ£€æŸ¥IDæ˜¯å¦å®Œæ•´\n",
        "    if set(submission['id']) == set(sample_submission['id']):\n",
        "        print(\"âœ… IDå®Œæ•´\")\n",
        "    else:\n",
        "        print(\"âŒ IDä¸å®Œæ•´\")\n",
        "        return False\n",
        "\n",
        "    # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦åˆæ³•\n",
        "    valid_labels = {'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
        "    if set(submission['label']) <= valid_labels:\n",
        "        print(\"âœ… æ ‡ç­¾åˆæ³•\")\n",
        "    else:\n",
        "        invalid_labels = set(submission['label']) - valid_labels\n",
        "        print(f\"âŒ å‘ç°éæ³•æ ‡ç­¾: {invalid_labels}\")\n",
        "        return False\n",
        "\n",
        "    print(\"ğŸ‰ æäº¤æ–‡ä»¶éªŒè¯é€šè¿‡ï¼\")\n",
        "    return True\n",
        "\n",
        "def main():\n",
        "    \"\"\"ä¸»å‡½æ•° - å®Œæ•´æµç¨‹ï¼ˆé€‚é…CIFAR-10çœŸå®æ•°æ®ï¼‰\"\"\"\n",
        "    print(\"ğŸš€ CIFAR-10 å›¾åƒåˆ†ç±»é¡¹ç›®å¼€å§‹\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # åˆå§‹åŒ–å˜é‡ï¼Œé¿å…NameError\n",
        "    X_train, y_train_onehot, X_test, test_ids = None, None, None, None\n",
        "    model, history, submission = None, None, None\n",
        "\n",
        "    try:\n",
        "        # 1. æ•°æ®åŠ è½½\n",
        "        print(\"æ­¥éª¤1: æ•°æ®åŠ è½½\")\n",
        "        train_df, test_df, sample_submission = load_cifar_data()\n",
        "\n",
        "        if train_df is None and test_df is None:\n",
        "            print(\"âš ï¸ è‡ªå®šä¹‰æ•°æ®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨Keraså†…ç½®CIFAR-10æ•°æ®é›†\")\n",
        "            X_train, y_train_onehot, X_test, y_test_onehot = prepare_cifar10_data()\n",
        "            test_ids = list(range(1, len(X_test) + 1))\n",
        "            # åˆ›å»ºç®€å•çš„æäº¤æ ·æœ¬æ ¼å¼\n",
        "            sample_submission = pd.DataFrame({\n",
        "                'id': test_ids,\n",
        "                'label': ['airplane'] * len(test_ids)  # å ä½ç¬¦\n",
        "            })\n",
        "        else:\n",
        "            # 2. æ•°æ®åˆ†æ\n",
        "            print(\"\\næ­¥éª¤2: æ•°æ®åˆ†æ\")\n",
        "            quick_data_analysis(train_df, test_df, sample_submission)\n",
        "\n",
        "            # 3. æ•°æ®é¢„å¤„ç†\n",
        "            print(\"\\næ­¥éª¤3: æ•°æ®é¢„å¤„ç†\")\n",
        "            X_train, y_train_onehot, X_test, test_ids = preprocess_data(train_df, test_df)\n",
        "\n",
        "        # 4. æ¨¡å‹åˆ›å»º\n",
        "        print(\"\\næ­¥éª¤4: æ¨¡å‹åˆ›å»º\")\n",
        "        model = create_model()\n",
        "        print(\"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ\")\n",
        "        print(f\"æ¨¡å‹å‚æ•°æ•°é‡: {model.count_params():,}\")\n",
        "\n",
        "        # æ˜¾ç¤ºæ¨¡å‹ç»“æ„\n",
        "        model.summary()\n",
        "\n",
        "        # 5. æ¨¡å‹è®­ç»ƒ\n",
        "        print(\"\\næ­¥éª¤5: æ¨¡å‹è®­ç»ƒ\")\n",
        "        if X_train is not None and y_train_onehot is not None:\n",
        "            model, history = train_model_enhanced(model, X_train, y_train_onehot)\n",
        "\n",
        "            if history is not None:\n",
        "                # 6. ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
        "                print(\"\\næ­¥éª¤6: è®­ç»ƒç»“æœå¯è§†åŒ–\")\n",
        "                plot_training_history(history)\n",
        "            else:\n",
        "                print(\"âŒ è®­ç»ƒå¤±è´¥ï¼Œæ— æ³•ç»§ç»­\")\n",
        "                return\n",
        "        else:\n",
        "            print(\"âŒ è®­ç»ƒæ•°æ®ä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹\")\n",
        "            return\n",
        "\n",
        "        # 7. ç”Ÿæˆé¢„æµ‹å’Œæäº¤æ–‡ä»¶\n",
        "        print(\"\\næ­¥éª¤7: ç”Ÿæˆæäº¤æ–‡ä»¶\")\n",
        "        if X_test is not None and sample_submission is not None:\n",
        "            submission = generate_submission_enhanced(model, X_test, test_ids, sample_submission)\n",
        "\n",
        "            if submission is not None:\n",
        "                # 8. éªŒè¯æäº¤æ–‡ä»¶\n",
        "                print(\"\\næ­¥éª¤8: éªŒè¯æäº¤æ–‡ä»¶\")\n",
        "                is_valid = validate_submission(submission, sample_submission)\n",
        "\n",
        "                if is_valid:\n",
        "                    print(\"ğŸ‰ é¡¹ç›®å®Œæˆï¼æäº¤æ–‡ä»¶å·²ç”Ÿæˆå¹¶éªŒè¯é€šè¿‡\")\n",
        "                else:\n",
        "                    print(\"âš ï¸ æäº¤æ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥\")\n",
        "            else:\n",
        "                print(\"âŒ æäº¤æ–‡ä»¶ç”Ÿæˆå¤±è´¥\")\n",
        "        else:\n",
        "            print(\"âŒ æµ‹è¯•æ•°æ®ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆæäº¤æ–‡ä»¶\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    finally:\n",
        "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
        "        temp_dir = '/content/temp_cifar'\n",
        "        if 'temp_dir' in locals():\n",
        "            try:\n",
        "                cleanup_temp_files(temp_dir)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"ç¨‹åºæ‰§è¡Œå®Œæ¯•\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # è®¾ç½®matplotlibåç«¯ï¼ˆé€‚é…Colabç¯å¢ƒï¼‰\n",
        "    import matplotlib\n",
        "    matplotlib.use('Agg')  # æˆ–è€… 'inline' å¦‚æœåœ¨Jupyterä¸­\n",
        "\n",
        "    # æ‰§è¡Œä¸»å‡½æ•°\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BNOe3ADlbNV",
        "outputId": "41016282-a89d-44d6-91d4-4a9457572941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ CIFAR-10 å›¾åƒåˆ†ç±»é¡¹ç›®å¼€å§‹\n",
            "==================================================\n",
            "æ­¥éª¤1: æ•°æ®åŠ è½½\n",
            "æ­£åœ¨æŒ‚è½½Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… æ‰¾åˆ°cifar-10.zipæ–‡ä»¶: /content/drive/MyDrive/cifar-10.zip\n",
            "æ–‡ä»¶å¤§å°: 715.4 MB\n",
            "æ­£åœ¨æ¢ç´¢zipæ–‡ä»¶å†…å®¹...\n",
            "zipæ–‡ä»¶ä¸­åŒ…å« 4 ä¸ªæ–‡ä»¶:\n",
            "  - sampleSubmission.csv\n",
            "  - test.7z\n",
            "  - train.7z\n",
            "  - trainLabels.csv\n",
            "\n",
            "æ‰¾åˆ° 2 ä¸ª7zæ–‡ä»¶:\n",
            "  - test.7z\n",
            "  - train.7z\n",
            "æ‰¾åˆ° 2 ä¸ªCSVæ–‡ä»¶:\n",
            "  - sampleSubmission.csv\n",
            "  - trainLabels.csv\n",
            "æ­£åœ¨è§£å‹æ–‡ä»¶...\n",
            "âœ… zipæ–‡ä»¶è§£å‹å®Œæˆ\n",
            "è§£å‹åçš„æ–‡ä»¶: ['train.7z', 'test.7z', 'trainLabels.csv', 'test', 'sampleSubmission.csv', 'train']\n",
            "âœ… åŠ è½½è®­ç»ƒæ ‡ç­¾æ•°æ®: (50000, 2)\n",
            "âœ… åŠ è½½æäº¤æ ·æœ¬: (300000, 2)\n",
            "æ­£åœ¨è§£å‹7zæ–‡ä»¶: train.7z\n",
            "âœ… train.7z è§£å‹å®Œæˆ\n",
            "âœ… åŠ è½½è®­ç»ƒå›¾ç‰‡ 50000 å¼ \n",
            "æ­£åœ¨è§£å‹7zæ–‡ä»¶: test.7z\n",
            "âœ… test.7z è§£å‹å®Œæˆ\n",
            "âœ… åŠ è½½æµ‹è¯•å›¾ç‰‡ 300000 å¼ \n",
            "\n",
            "ğŸ“Š è®­ç»ƒæ•°æ®æ¦‚è§ˆ:\n",
            "å½¢çŠ¶: (50000, 3)\n",
            "åˆ—å: ['id', 'label', 'image']\n",
            "   id       label                                              image\n",
            "0   1        frog  [[[59, 62, 63], [43, 46, 45], [50, 48, 43], [6...\n",
            "1   2       truck  [[[125, 125, 116], [110, 101, 91], [102, 90, 8...\n",
            "2   3       truck  [[[62, 64, 44], [50, 50, 26], [46, 44, 19], [4...\n",
            "3   4        deer  [[[203, 206, 208], [201, 202, 202], [208, 209,...\n",
            "4   5  automobile  [[[62, 55, 7], [61, 55, 7], [60, 55, 6], [59, ...\n",
            "\n",
            "ğŸ“Š æµ‹è¯•æ•°æ®æ¦‚è§ˆ:\n",
            "å½¢çŠ¶: (300000, 2)\n",
            "åˆ—å: ['id', 'image']\n",
            "   id                                              image\n",
            "0   1  [[[134, 116, 78], [144, 127, 91], [145, 128, 9...\n",
            "1   2  [[[130, 119, 139], [131, 119, 140], [132, 120,...\n",
            "2   3  [[[128, 138, 79], [109, 122, 67], [104, 123, 6...\n",
            "3   4  [[[254, 254, 254], [250, 250, 250], [251, 251,...\n",
            "4   5  [[[170, 149, 128], [185, 164, 141], [193, 171,...\n",
            "\n",
            "ğŸ“Š æäº¤æ ·æœ¬æ¦‚è§ˆ:\n",
            "å½¢çŠ¶: (300000, 2)\n",
            "åˆ—å: ['id', 'label']\n",
            "   id label\n",
            "0   1   cat\n",
            "1   2   cat\n",
            "2   3   cat\n",
            "3   4   cat\n",
            "4   5   cat\n",
            "\n",
            "ä¸´æ—¶æ–‡ä»¶ä¿å­˜åœ¨: /content/temp_cifar\n",
            "å¦‚éœ€æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œè¯·è°ƒç”¨: cleanup_temp_files(temp_dir)\n",
            "\n",
            "æ­¥éª¤2: æ•°æ®åˆ†æ\n",
            "\n",
            "=== æ•°æ®åˆ†æ ===\n",
            "è®­ç»ƒæ•°æ®ä¿¡æ¯:\n",
            "  å½¢çŠ¶: (50000, 3)\n",
            "  åˆ—å: ['id', 'label', 'image']\n",
            "  å‰å‡ è¡Œ:\n",
            "   id  label                                              image\n",
            "0   1   frog  [[[59, 62, 63], [43, 46, 45], [50, 48, 43], [6...\n",
            "1   2  truck  [[[125, 125, 116], [110, 101, 91], [102, 90, 8...\n",
            "\n",
            "æ ‡ç­¾åˆ†å¸ƒ:\n",
            "  airplane: 5000 å¼ \n",
            "  automobile: 5000 å¼ \n",
            "  bird: 5000 å¼ \n",
            "  cat: 5000 å¼ \n",
            "  deer: 5000 å¼ \n",
            "  dog: 5000 å¼ \n",
            "  frog: 5000 å¼ \n",
            "  horse: 5000 å¼ \n",
            "  ship: 5000 å¼ \n",
            "  truck: 5000 å¼ \n",
            "\n",
            "æµ‹è¯•æ•°æ®ä¿¡æ¯:\n",
            "  å½¢çŠ¶: (300000, 2)\n",
            "  åˆ—å: ['id', 'image']\n",
            "  å‰å‡ è¡Œ:\n",
            "   id                                              image\n",
            "0   1  [[[134, 116, 78], [144, 127, 91], [145, 128, 9...\n",
            "1   2  [[[130, 119, 139], [131, 119, 140], [132, 120,...\n",
            "\n",
            "æäº¤æ ·æœ¬ä¿¡æ¯:\n",
            "  å½¢çŠ¶: (300000, 2)\n",
            "  åˆ—å: ['id', 'label']\n",
            "  å‰å‡ è¡Œ:\n",
            "   id label\n",
            "0   1   cat\n",
            "1   2   cat\n",
            "\n",
            "æ­¥éª¤3: æ•°æ®é¢„å¤„ç†\n",
            "\n",
            "=== æ•°æ®é¢„å¤„ç† ===\n",
            "æ ‡ç­¾è½¬æ¢å®Œæˆï¼šfrog -> 6\n",
            "âœ… è®­ç»ƒæ•°æ®å·²ä¸º32x32x3å›¾åƒæ ¼å¼\n",
            "âœ… æµ‹è¯•æ•°æ®å·²ä¸º32x32x3å›¾åƒæ ¼å¼\n",
            "âœ… è®­ç»ƒæ•°æ®æ ‡å‡†åŒ–å®Œæˆï¼Œåƒç´ å€¼èŒƒå›´: [0.000, 1.000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ä¿®å¤åçš„CIFAR-10æ¨¡å‹è®­ç»ƒä»£ç \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 6. åˆ›å»ºæ¨¡å‹\n",
        "def create_model():\n",
        "    \"\"\"åˆ›å»ºæ”¹è¿›çš„CNNæ¨¡å‹\"\"\"\n",
        "    model = keras.Sequential([\n",
        "        # ç¬¬ä¸€å±‚å·ç§¯å—\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # ç¬¬äºŒå±‚å·ç§¯å—\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # ç¬¬ä¸‰å±‚å·ç§¯å—\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # å…¨è¿æ¥å±‚\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# 7. è®­ç»ƒæ¨¡å‹\n",
        "def train_model_enhanced(model, X_train, y_train):\n",
        "    \"\"\"å¢å¼ºç‰ˆæ¨¡å‹è®­ç»ƒå‡½æ•°\"\"\"\n",
        "    print(\"\\n=== å¼€å§‹è®­ç»ƒ ===\")\n",
        "\n",
        "    # æ£€æŸ¥æ•°æ®\n",
        "    if X_train is None or y_train is None:\n",
        "        print(\"âŒ è®­ç»ƒæ•°æ®æœªæ­£ç¡®åŠ è½½ï¼Œæ— æ³•è®­ç»ƒ\")\n",
        "        return None, None\n",
        "\n",
        "    # æ£€æŸ¥æ•°æ®å½¢çŠ¶\n",
        "    if len(X_train.shape) != 4 or X_train.shape[1:] != (32, 32, 3):\n",
        "        print(f\"âŒ è®­ç»ƒæ•°æ®å½¢çŠ¶ä¸æ­£ç¡®: {X_train.shape}, æœŸæœ›: (N, 32, 32, 3)\")\n",
        "        return None, None\n",
        "\n",
        "    if len(y_train.shape) != 2 or y_train.shape[1] != 10:\n",
        "        print(f\"âŒ æ ‡ç­¾æ•°æ®å½¢çŠ¶ä¸æ­£ç¡®: {y_train.shape}, æœŸæœ›: (N, 10)\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"âœ… æ•°æ®æ£€æŸ¥é€šè¿‡:\")\n",
        "    print(f\"   è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train.shape}\")\n",
        "    print(f\"   æ ‡ç­¾æ•°æ®å½¢çŠ¶: {y_train.shape}\")\n",
        "\n",
        "    # ç¼–è¯‘æ¨¡å‹\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # åˆ†å‰²éªŒè¯é›†\n",
        "        X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "            X_train, y_train,\n",
        "            test_size=0.2,\n",
        "            random_state=42,\n",
        "            stratify=np.argmax(y_train, axis=1)\n",
        "        )\n",
        "\n",
        "        print(f\"âœ… æ•°æ®åˆ†å‰²å®Œæˆ:\")\n",
        "        print(f\"   è®­ç»ƒé›†: {X_train_split.shape[0]} å¼ \")\n",
        "        print(f\"   éªŒè¯é›†: {X_val.shape[0]} å¼ \")\n",
        "\n",
        "        # æ•°æ®å¢å¼º\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=15,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            horizontal_flip=True,\n",
        "            zoom_range=0.1,\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "\n",
        "        # å›è°ƒå‡½æ•°\n",
        "        callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor='val_accuracy',\n",
        "                patience=15,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=7,\n",
        "                min_lr=1e-7,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
        "\n",
        "        # è®¡ç®—æ­¥æ•°\n",
        "        batch_size = 32  # å‡å°æ‰¹æ¬¡å¤§å°é¿å…å†…å­˜é—®é¢˜\n",
        "        steps_per_epoch = max(1, len(X_train_split) // batch_size)\n",
        "\n",
        "        # è®­ç»ƒæ¨¡å‹\n",
        "        history = model.fit(\n",
        "            datagen.flow(X_train_split, y_train_split, batch_size=batch_size),\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            epochs=50,  # å‡å°‘åˆå§‹epochs\n",
        "            validation_data=(X_val, y_val),\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # è®­ç»ƒå®Œæˆåçš„è¯„ä¼°\n",
        "        print(\"\\n=== è®­ç»ƒå®Œæˆ ===\")\n",
        "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "        print(f\"âœ… æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}\")\n",
        "        print(f\"âœ… æœ€ç»ˆéªŒè¯æŸå¤±: {val_loss:.4f}\")\n",
        "\n",
        "        return model, history\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\")\n",
        "        print(\"å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
        "        print(\"1. æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®\")\n",
        "        print(\"2. å‡å°æ‰¹æ¬¡å¤§å°\")\n",
        "        print(\"3. æ£€æŸ¥GPUå†…å­˜æ˜¯å¦è¶³å¤Ÿ\")\n",
        "        return None, None\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨\"\"\"\n",
        "    if history is None:\n",
        "        print(\"âŒ æ²¡æœ‰è®­ç»ƒå†å²æ•°æ®å¯ä»¥ç»˜åˆ¶\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "        # å‡†ç¡®ç‡å›¾è¡¨\n",
        "        ax1.plot(history.history['accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡')\n",
        "        ax1.plot(history.history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡')\n",
        "        ax1.set_title('æ¨¡å‹å‡†ç¡®ç‡')\n",
        "        ax1.set_xlabel('è½®æ¬¡')\n",
        "        ax1.set_ylabel('å‡†ç¡®ç‡')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # æŸå¤±å›¾è¡¨\n",
        "        ax2.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')\n",
        "        ax2.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')\n",
        "        ax2.set_title('æ¨¡å‹æŸå¤±')\n",
        "        ax2.set_xlabel('è½®æ¬¡')\n",
        "        ax2.set_ylabel('æŸå¤±')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ç»˜å›¾æ—¶å‡ºç°é”™è¯¯: {str(e)}\")\n",
        "\n",
        "# æ•°æ®å‡†å¤‡å‡½æ•°ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
        "def prepare_cifar10_data():\n",
        "    \"\"\"å‡†å¤‡CIFAR-10æ•°æ®\"\"\"\n",
        "    try:\n",
        "        # åŠ è½½CIFAR-10æ•°æ®\n",
        "        (X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "        # æ•°æ®é¢„å¤„ç†\n",
        "        X_train = X_train.astype('float32') / 255.0\n",
        "        X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "        # æ ‡ç­¾one-hotç¼–ç \n",
        "        y_train_onehot = keras.utils.to_categorical(y_train, 10)\n",
        "        y_test_onehot = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "        print(f\"âœ… æ•°æ®åŠ è½½å®Œæˆ:\")\n",
        "        print(f\"   è®­ç»ƒé›†: {X_train.shape}\")\n",
        "        print(f\"   æµ‹è¯•é›†: {X_test.shape}\")\n",
        "        print(f\"   è®­ç»ƒæ ‡ç­¾: {y_train_onehot.shape}\")\n",
        "        print(f\"   æµ‹è¯•æ ‡ç­¾: {y_test_onehot.shape}\")\n",
        "\n",
        "        return X_train, y_train_onehot, X_test, y_test_onehot\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# ä¸»æ‰§è¡Œä»£ç \n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 50)\n",
        "    print(\"CIFAR-10 CNNæ¨¡å‹è®­ç»ƒ\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # æ­¥éª¤1: å‡†å¤‡æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
        "    print(\"\\næ­¥éª¤1ï¼šå‡†å¤‡æ•°æ®\")\n",
        "    print(\"-\" * 30)\n",
        "    # X_train, y_train_onehot, X_test, y_test_onehot = prepare_cifar10_data()\n",
        "\n",
        "    # æ­¥éª¤2: åˆ›å»ºæ¨¡å‹\n",
        "    print(\"\\næ­¥éª¤2ï¼šåˆ›å»ºæ¨¡å‹\")\n",
        "    print(\"-\" * 30)\n",
        "    model = create_model()\n",
        "    print(f\"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ\")\n",
        "    print(f\"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {model.count_params():,}\")\n",
        "    print(f\"ğŸ“‹ æ¨¡å‹ç»“æ„:\")\n",
        "    model.summary()\n",
        "\n",
        "    # æ­¥éª¤3: è®­ç»ƒæ¨¡å‹ï¼ˆéœ€è¦ç¡®ä¿X_trainå’Œy_train_onehotå·²å®šä¹‰ï¼‰\n",
        "    print(\"\\næ­¥éª¤3ï¼šè®­ç»ƒæ¨¡å‹\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # æ£€æŸ¥å˜é‡æ˜¯å¦å­˜åœ¨\n",
        "    try:\n",
        "        # è¿™é‡Œå‡è®¾X_trainå’Œy_train_onehotå·²ç»åœ¨ä¹‹å‰çš„ä»£ç ä¸­å®šä¹‰\n",
        "        # å¦‚æœæ²¡æœ‰ï¼Œè¯·å–æ¶ˆæ³¨é‡Šä¸Šé¢çš„æ•°æ®å‡†å¤‡ä»£ç \n",
        "        model_trained, history = train_model_enhanced(model, X_train, y_train_onehot)\n",
        "\n",
        "        if model_trained is not None and history is not None:\n",
        "            print(\"âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸå®Œæˆï¼\")\n",
        "\n",
        "            # ç»˜åˆ¶è®­ç»ƒå†å²\n",
        "            plot_training_history(history)\n",
        "\n",
        "            # ä¿å­˜æ¨¡å‹\n",
        "            try:\n",
        "                model_path = 'cifar10_model.h5'\n",
        "                model_trained.save(model_path)\n",
        "                print(f\"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {str(e)}\")\n",
        "                print(\"å°è¯•ä¿å­˜ä¸ºSavedModelæ ¼å¼...\")\n",
        "                try:\n",
        "                    model_trained.save('cifar10_model')\n",
        "                    print(\"âœ… æ¨¡å‹å·²ä¿å­˜ä¸ºSavedModelæ ¼å¼\")\n",
        "                except Exception as e2:\n",
        "                    print(f\"âŒ SavedModelä¿å­˜ä¹Ÿå¤±è´¥: {str(e2)}\")\n",
        "        else:\n",
        "            print(\"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥\")\n",
        "\n",
        "    except NameError as e:\n",
        "        print(f\"âŒ å˜é‡æœªå®šä¹‰: {str(e)}\")\n",
        "        print(\"è¯·ç¡®ä¿X_trainå’Œy_train_onehotå·²ç»æ­£ç¡®åŠ è½½å’Œé¢„å¤„ç†\")\n",
        "        print(\"å¯ä»¥å–æ¶ˆæ³¨é‡Šæ•°æ®å‡†å¤‡ä»£ç æ¥åŠ è½½CIFAR-10æ•°æ®\")"
      ],
      "metadata": {
        "id": "A0iTuB67trim",
        "outputId": "c5392f07-fd27-4e32-f738-4f32b8467bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "CIFAR-10 CNNæ¨¡å‹è®­ç»ƒ\n",
            "==================================================\n",
            "\n",
            "æ­¥éª¤1ï¼šå‡†å¤‡æ•°æ®\n",
            "------------------------------\n",
            "\n",
            "æ­¥éª¤2ï¼šåˆ›å»ºæ¨¡å‹\n",
            "------------------------------\n",
            "âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ\n",
            "ğŸ“Š æ¨¡å‹å‚æ•°é‡: 490,922\n",
            "ğŸ“‹ æ¨¡å‹ç»“æ„:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m896\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚         \u001b[38;5;34m9,248\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_11          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m36,928\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_12          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      â”‚       \u001b[38;5;34m147,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚        \u001b[38;5;34m66,048\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_13          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m131,328\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_14          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m2,570\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_11          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_12          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_13          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_14          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m490,922\u001b[0m (1.87 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">490,922</span> (1.87 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m488,938\u001b[0m (1.87 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">488,938</span> (1.87 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "æ­¥éª¤3ï¼šè®­ç»ƒæ¨¡å‹\n",
            "------------------------------\n",
            "âŒ å˜é‡æœªå®šä¹‰: name 'X_train' is not defined\n",
            "è¯·ç¡®ä¿X_trainå’Œy_train_onehotå·²ç»æ­£ç¡®åŠ è½½å’Œé¢„å¤„ç†\n",
            "å¯ä»¥å–æ¶ˆæ³¨é‡Šæ•°æ®å‡†å¤‡ä»£ç æ¥åŠ è½½CIFAR-10æ•°æ®\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. è®­ç»ƒæ¨¡å‹\n",
        "def train_model_enhanced(model, X_train, y_train):\n",
        "    \"\"\"å¢å¼ºç‰ˆæ¨¡å‹è®­ç»ƒå‡½æ•°\"\"\"\n",
        "    print(\"\\n=== å¼€å§‹è®­ç»ƒ ===\")\n",
        "\n",
        "    if X_train is None or y_train is None:\n",
        "        print(\"âŒ è®­ç»ƒæ•°æ®æœªæ­£ç¡®åŠ è½½ï¼Œæ— æ³•è®­ç»ƒ\")\n",
        "        return None, None\n",
        "\n",
        "    # ç¼–è¯‘æ¨¡å‹\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # åˆ†å‰²éªŒè¯é›†\n",
        "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42, stratify=np.argmax(y_train, axis=1)\n",
        "    )\n",
        "\n",
        "    print(f\"âœ… æ•°æ®åˆ†å‰²å®Œæˆ:\")\n",
        "    print(f\"   è®­ç»ƒé›†: {X_train_split.shape[0]} å¼ \")\n",
        "    print(f\"   éªŒè¯é›†: {X_val.shape[0]} å¼ \")\n",
        "\n",
        "    # æ•°æ®å¢å¼º\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.1,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # å›è°ƒå‡½æ•°\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n",
        "\n",
        "    # è®­ç»ƒæ¨¡å‹\n",
        "    history = model.fit(\n",
        "        datagen.flow(X_train_split, y_train_split, batch_size=64),\n",
        "        steps_per_epoch=len(X_train_split) // 64,\n",
        "        epochs=100,  # è®¾ç½®è¾ƒå¤§å€¼ï¼Œä¾é EarlyStoppingè‡ªåŠ¨åœæ­¢\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # è®­ç»ƒå®Œæˆåçš„è¯„ä¼°\n",
        "    print(\"\\n=== è®­ç»ƒå®Œæˆ ===\")\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"âœ… æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}\")\n",
        "    print(f\"âœ… æœ€ç»ˆéªŒè¯æŸå¤±: {val_loss:.4f}\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨\"\"\"\n",
        "    if history is None:\n",
        "        return\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # å‡†ç¡®ç‡å›¾è¡¨\n",
        "    ax1.plot(history.history['accuracy'], label='è®­ç»ƒå‡†ç¡®ç‡')\n",
        "    ax1.plot(history.history['val_accuracy'], label='éªŒè¯å‡†ç¡®ç‡')\n",
        "    ax1.set_title('æ¨¡å‹å‡†ç¡®ç‡')\n",
        "    ax1.set_xlabel('è½®æ¬¡')\n",
        "    ax1.set_ylabel('å‡†ç¡®ç‡')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # æŸå¤±å›¾è¡¨\n",
        "    ax2.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')\n",
        "    ax2.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')\n",
        "    ax2.set_title('æ¨¡å‹æŸå¤±')\n",
        "    ax2.set_xlabel('è½®æ¬¡')\n",
        "    ax2.set_ylabel('æŸå¤±')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# æ‰§è¡Œæ­¥éª¤7\n",
        "print(\"=\" * 50)\n",
        "print(\"æ­¥éª¤7ï¼šè®­ç»ƒæ¨¡å‹\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# è®­ç»ƒæ¨¡å‹\n",
        "model, history = train_model_enhanced(model, X_train, y_train_onehot)\n",
        "\n",
        "if model is not None and history is not None:\n",
        "    print(\"âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸå®Œæˆï¼\")\n",
        "\n",
        "    # ç»˜åˆ¶è®­ç»ƒå†å²\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # ä¿å­˜æ¨¡å‹\n",
        "    model_path = '/content/drive/MyDrive/cifar10_model.h5'\n",
        "    model.save(model_path)\n",
        "    print(f\"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}\")\n",
        "else:\n",
        "    print(\"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥\")"
      ],
      "metadata": {
        "id": "WvHgx3XnuNDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. ç”Ÿæˆæäº¤æ–‡ä»¶\n",
        "def generate_submission_enhanced(model, X_test, test_ids, sample_submission):\n",
        "    \"\"\"å¢å¼ºç‰ˆæäº¤æ–‡ä»¶ç”Ÿæˆå‡½æ•°\"\"\"\n",
        "    print(\"\\n=== ç”Ÿæˆæäº¤æ–‡ä»¶ ===\")\n",
        "\n",
        "    if X_test is None or sample_submission is None:\n",
        "        print(\"âŒ æµ‹è¯•æ•°æ®æˆ–æäº¤æ ·æœ¬æœªæ­£ç¡®åŠ è½½ï¼Œæ— æ³•ç”Ÿæˆæäº¤æ–‡ä»¶\")\n",
        "        return None\n",
        "\n",
        "    if model is None:\n",
        "        print(\"âŒ æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•ç”Ÿæˆé¢„æµ‹\")\n",
        "        return None\n",
        "\n",
        "    print(f\"ğŸ“Š å¼€å§‹é¢„æµ‹ {len(X_test)} å¼ æµ‹è¯•å›¾ç‰‡...\")\n",
        "\n",
        "    # åˆ†æ‰¹é¢„æµ‹ï¼ˆé¿å…å†…å­˜ä¸è¶³ï¼‰\n",
        "    batch_size = 1000\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(0, len(X_test), batch_size):\n",
        "        end_idx = min(i + batch_size, len(X_test))\n",
        "        batch_predictions = model.predict(X_test[i:end_idx], verbose=0)\n",
        "        predictions.append(batch_predictions)\n",
        "\n",
        "        # æ˜¾ç¤ºè¿›åº¦\n",
        "        progress = (end_idx / len(X_test)) * 100\n",
        "        print(f\"é¢„æµ‹è¿›åº¦: {progress:.1f}% ({end_idx}/{len(X_test)})\")\n",
        "\n",
        "    # åˆå¹¶æ‰€æœ‰é¢„æµ‹ç»“æœ\n",
        "    predictions = np.vstack(predictions)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # å°†æ•°å­—æ ‡ç­¾è½¬å›å­—ç¬¦ä¸²æ ‡ç­¾\n",
        "    int_to_label = {\n",
        "        0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
        "        5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'\n",
        "    }\n",
        "\n",
        "    predicted_labels = [int_to_label[pred] for pred in predicted_classes]\n",
        "\n",
        "    # åˆ›å»ºæäº¤æ–‡ä»¶\n",
        "    submission = sample_submission.copy()\n",
        "    submission['label'] = predicted_labels\n",
        "\n",
        "    # éªŒè¯æäº¤æ–‡ä»¶æ ¼å¼\n",
        "    print(f\"\\nğŸ“‹ æäº¤æ–‡ä»¶éªŒè¯:\")\n",
        "    print(f\"   å½¢çŠ¶: {submission.shape}\")\n",
        "    print(f\"   åˆ—å: {list(submission.columns)}\")\n",
        "    print(f\"   IDèŒƒå›´: {submission['id'].min()} - {submission['id'].max()}\")\n",
        "    print(f\"   æ ‡ç­¾ç±»å‹: {submission['label'].dtype}\")\n",
        "\n",
        "    # æ£€æŸ¥é¢„æµ‹åˆ†å¸ƒ\n",
        "    print(f\"\\nğŸ“Š é¢„æµ‹ç»“æœåˆ†å¸ƒ:\")\n",
        "    label_counts = submission['label'].value_counts().sort_index()\n",
        "    for label, count in label_counts.items():\n",
        "        percentage = (count / len(submission)) * 100\n",
        "        print(f\"   {label}: {count:,} å¼  ({percentage:.1f}%)\")\n",
        "\n",
        "    # ä¿å­˜åˆ°Drive\n",
        "    submission_path = '/content/drive/MyDrive/cifar10_submission.csv'\n",
        "    submission.to_csv(submission_path, index=False)\n",
        "\n",
        "    print(f\"\\nâœ… æäº¤æ–‡ä»¶å·²ä¿å­˜: {submission_path}\")\n",
        "    print(f\"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(submission_path) / (1024*1024):.1f} MB\")\n",
        "\n",
        "    # æ˜¾ç¤ºæäº¤æ–‡ä»¶å‰å‡ è¡Œ\n",
        "    print(f\"\\nğŸ“ æäº¤æ–‡ä»¶é¢„è§ˆ:\")\n",
        "    print(submission.head(10))\n",
        "\n",
        "    return submission\n",
        "\n",
        "def validate_submission(submission, sample_submission):\n",
        "    \"\"\"éªŒè¯æäº¤æ–‡ä»¶çš„æ­£ç¡®æ€§\"\"\"\n",
        "    print(\"\\n=== æäº¤æ–‡ä»¶éªŒè¯ ===\")\n",
        "\n",
        "    # æ£€æŸ¥å½¢çŠ¶\n",
        "    if submission.shape == sample_submission.shape:\n",
        "        print(\"âœ… æ–‡ä»¶å½¢çŠ¶æ­£ç¡®\")\n",
        "    else:\n",
        "        print(f\"âŒ æ–‡ä»¶å½¢çŠ¶é”™è¯¯: {submission.shape} vs {sample_submission.shape}\")\n",
        "        return False\n",
        "\n",
        "    # æ£€æŸ¥åˆ—å\n",
        "    if list(submission.columns) == list(sample_submission.columns):\n",
        "        print(\"âœ… åˆ—åæ­£ç¡®\")\n",
        "    else:\n",
        "        print(f\"âŒ åˆ—åé”™è¯¯: {list(submission.columns)} vs {list(sample_submission.columns)}\")\n",
        "        return False\n",
        "\n",
        "    # æ£€æŸ¥IDæ˜¯å¦å®Œæ•´\n",
        "    if set(submission['id']) == set(sample_submission['id']):\n",
        "        print(\"âœ… IDå®Œæ•´\")\n",
        "    else:\n",
        "        print(\"âŒ IDä¸å®Œæ•´\")\n",
        "        return False\n",
        "\n",
        "    # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦åˆæ³•\n",
        "    valid_labels = {'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
        "    if set(submission['label']) <= valid_labels:\n",
        "        print(\"âœ… æ ‡ç­¾åˆæ³•\")\n",
        "    else:\n",
        "        invalid_labels = set(submission['label']) - valid_labels\n",
        "        print(f\"âŒ å‘ç°éæ³•æ ‡ç­¾: {invalid_labels}\")\n",
        "        return False\n",
        "\n",
        "    print(\"ğŸ‰ æäº¤æ–‡ä»¶éªŒè¯é€šè¿‡ï¼\")\n",
        "    return True\n",
        "\n",
        "# æ‰§è¡Œæ­¥éª¤8\n",
        "print(\"=\" * 50)\n",
        "print(\"æ­¥éª¤8ï¼šç”Ÿæˆæäº¤æ–‡ä»¶\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ç”Ÿæˆæäº¤æ–‡ä»¶\n",
        "submission = generate_submission_enhanced(model, X_test, test_ids, sample_submission)\n",
        "\n",
        "if submission is not None:\n",
        "    # éªŒè¯æäº¤æ–‡ä»¶\n",
        "    is_valid = validate_submission(submission, sample_submission)\n",
        "\n",
        "    if is_valid:\n",
        "        print(\"\\nğŸ‰ ä»»åŠ¡å®Œæˆï¼\")\n",
        "        print(\"=\" * 50)\n",
        "        print(\"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ\")\n",
        "        print(\"âœ… æäº¤æ–‡ä»¶ç”ŸæˆæˆåŠŸ\")\n",
        "        print(\"âœ… æ–‡ä»¶éªŒè¯é€šè¿‡\")\n",
        "        print(\"ğŸš€ å¯ä»¥ç›´æ¥æäº¤åˆ°Kaggle!\")\n",
        "\n",
        "        # æœ€ç»ˆç»Ÿè®¡\n",
        "        print(f\"\\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:\")\n",
        "        print(f\"   è®­ç»ƒæ ·æœ¬: 50,000 å¼ \")\n",
        "        print(f\"   æµ‹è¯•æ ·æœ¬: 300,000 å¼ \")\n",
        "        print(f\"   æ¨¡å‹å‚æ•°: {model.count_params():,}\")\n",
        "        print(f\"   æäº¤æ–‡ä»¶: /content/drive/MyDrive/cifar10_submission.csv\")\n",
        "    else:\n",
        "        print(\"âŒ æäº¤æ–‡ä»¶éªŒè¯å¤±è´¥\")\n",
        "else:\n",
        "    print(\"âŒ æäº¤æ–‡ä»¶ç”Ÿæˆå¤±è´¥\")"
      ],
      "metadata": {
        "id": "m9kH-D1JuQE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import py7zr  # éœ€å…ˆå®‰è£…ï¼š!pip install py7zr\n",
        "from google.colab import drive\n",
        "\n",
        "# æŒ‚è½½ Google Driveï¼ˆè‹¥æ–‡ä»¶åœ¨ Drive ä¸­ï¼Œéœ€æ­¤æ­¥éª¤è®¿é—®æ–‡ä»¶ï¼‰\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1. è§£å‹ cifar-10.zip åˆ°å½“å‰ç›®å½•ï¼ˆå·²æœ‰çš„è§£å‹é€»è¾‘ï¼Œå¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰\n",
        "zip_path = '/content/drive/MyDrive/cifar-10.zip'\n",
        "extract_dir = '.'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "print(\"âœ… zip æ–‡ä»¶å·²è§£å‹åˆ°å½“å‰ç›®å½•\")\n",
        "\n",
        "# 2. å®šä¹‰ 7z æ–‡ä»¶è·¯å¾„ï¼ˆå‡è®¾è§£å‹å test.7z å’Œ train.7z åœ¨å½“å‰ç›®å½•ï¼‰\n",
        "test_7z_path = os.path.join(extract_dir, 'test.7z')\n",
        "train_7z_path = os.path.join(extract_dir, 'train.7z')\n",
        "\n",
        "# 3. è§£å‹ test.7z\n",
        "try:\n",
        "    with py7zr.SevenZipFile(test_7z_path, mode='r') as archive:\n",
        "        archive.extractall(path=extract_dir)\n",
        "    print(\"âœ… test.7z å·²æˆåŠŸè§£å‹\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ è§£å‹ test.7z å¤±è´¥: {e}\")\n",
        "\n",
        "# 4. è§£å‹ train.7z\n",
        "try:\n",
        "    with py7zr.SevenZipFile(train_7z_path, mode='r') as archive:\n",
        "        archive.extractall(path=extract_dir)\n",
        "    print(\"âœ… train.7z å·²æˆåŠŸè§£å‹\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ è§£å‹ train.7z å¤±è´¥: {e}\")"
      ],
      "metadata": {
        "id": "mPAmIBVqSsrw",
        "outputId": "abd59951-a334-4708-8061-ba71b415955f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… zip æ–‡ä»¶å·²è§£å‹åˆ°å½“å‰ç›®å½•\n",
            "âœ… test.7z å·²æˆåŠŸè§£å‹\n",
            "âœ… train.7z å·²æˆåŠŸè§£å‹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æ­¥éª¤1ï¼šå®‰è£…py7zr\n",
        "!pip install py7zr"
      ],
      "metadata": {
        "id": "1wcrQnRHNyqt",
        "outputId": "ff67bae0-2043-4b2c-b01a-5ba668c6d7c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py7zr\n",
            "  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting texttable (from py7zr)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (3.23.0)\n",
            "Collecting brotli>=1.1.0 (from py7zr)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from py7zr) (5.9.5)\n",
            "Collecting pyzstd>=0.16.1 (from py7zr)\n",
            "  Downloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting pyppmd<1.3.0,>=1.1.0 (from py7zr)\n",
            "  Downloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.13.2 in /usr/local/lib/python3.11/dist-packages (from pyzstd>=0.16.1->py7zr) (4.14.0)\n",
            "Downloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pybcj, multivolumefile, inflate64, py7zr\n",
            "Successfully installed brotli-1.1.0 inflate64-1.0.3 multivolumefile-0.2.3 py7zr-1.0.0 pybcj-1.0.6 pyppmd-1.2.0 pyzstd-0.17.0 texttable-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMkaBMEunbpD",
        "outputId": "da8ac05a-45f6-4bf5-8c0b-28273830b00f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "æ¬¢è¿ä½¿ç”¨ Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}